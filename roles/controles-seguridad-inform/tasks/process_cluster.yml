---
# ---------------------------------------------------------
# CONEXIÓN HUB-TO-SPOKE: Extraer kubeconfig del managed cluster desde el Hub
# Usa la credencial OpenShift/Kubernetes del Job Template (K8S_AUTH_* o KUBECONFIG),
# no el CLI 'oc', para compatibilidad con credenciales tipo Bearer Token en AAP.
# ---------------------------------------------------------
- name: "[CONN] Obtener kubeconfig del managed cluster desde el Hub (admin-kubeconfig)"
  when: target_cluster_name is defined and target_cluster_name | length > 0
  block:
    - name: Obtener secret admin-kubeconfig del Hub con credencial del Job Template
      kubernetes.core.k8s_info:
        kind: Secret
        name: admin-kubeconfig
        namespace: "{{ target_cluster_name }}"
      register: hub_secret
      # Sin kubeconfig: usa K8S_AUTH_* o KUBECONFIG inyectados por la credencial OpenShift/Kubernetes en AAP

    - name: Decodificar kubeconfig y guardar en archivo temporal
      ansible.builtin.copy:
        content: "{{ hub_secret.resources[0].data.kubeconfig | b64decode }}"
        dest: "/tmp/kubeconfig-{{ target_cluster_name }}"
        mode: '0600'
      when:
        - hub_secret.resources is defined
        - hub_secret.resources | length > 0
        - hub_secret.resources[0].data.kubeconfig is defined

    - name: Establecer ruta del kubeconfig dinámico
      ansible.builtin.set_fact:
        dynamic_kubeconfig_path: "/tmp/kubeconfig-{{ target_cluster_name }}"
      when:
        - hub_secret.resources is defined
        - hub_secret.resources | length > 0
        - hub_secret.resources[0].data.kubeconfig is defined

# Verificar que el kubeconfig existe en el controlador y exponer la ruta al host que ejecuta las tareas
# (evita que las tareas usen el contexto por defecto = Hub cuando la extracción falla)
- name: "[CONN] Verificar que el kubeconfig del spoke existe en el controlador"
  ansible.builtin.stat:
    path: "/tmp/kubeconfig-{{ target_cluster_name }}"
  register: kubeconfig_file_stat
  when: target_cluster_name is defined and target_cluster_name | length > 0

- name: "[CONN] Mostrar motivo del fallo de extracción (diagnóstico)"
  ansible.builtin.debug:
    msg: |
      Diagnóstico extracción kubeconfig para '{{ target_cluster_name }}':
      - Método: kubernetes.core.k8s_info (credencial OpenShift/Kubernetes del Job Template).
      - Secret consultado: admin-kubeconfig en namespace '{{ target_cluster_name }}'.
      - k8s_info falló: {{ hub_secret.failed | default(false) }}
      - Recursos encontrados: {{ (hub_secret.resources | default([])) | length }}
      - Error (si hubo): {{ (hub_secret.msg | default('')) | trim }}
      Verifique: credencial del HUB ACM asociada al Job Template; que el secret admin-kubeconfig exista en el namespace '{{ target_cluster_name }}' en el Hub.
  when:
    - target_cluster_name is defined
    - target_cluster_name | length > 0
    - not kubeconfig_file_stat.stat.exists | default(false)

- name: "[CONN] Fallar si no se pudo extraer el kubeconfig del spoke"
  ansible.builtin.fail:
    msg: |
      No se pudo obtener el kubeconfig del cluster '{{ target_cluster_name }}' desde el Hub.
      Verifique:
      1) Credencial del HUB ACM (OpenShift/Kubernetes) asociada al Job Template; el playbook usa esa credencial para conectar al Hub y leer el secret admin-kubeconfig.
      2) El secret admin-kubeconfig existe en el namespace '{{ target_cluster_name }}' en el Hub (debe coincidir con el nombre del managed cluster en ACM).
      3) Los nombres en survey_target_clusters coinciden con los namespaces de los managed clusters en el Hub.
  when:
    - target_cluster_name is defined
    - target_cluster_name | length > 0
    - not kubeconfig_file_stat.stat.exists | default(false)

- name: "[CONN] Exponer ruta del kubeconfig al host que ejecuta las tareas"
  ansible.builtin.set_fact:
    dynamic_kubeconfig_path: "/tmp/kubeconfig-{{ target_cluster_name }}"
  when:
    - target_cluster_name is defined
    - target_cluster_name | length > 0
    - kubeconfig_file_stat.stat.exists | default(false)

- name: "[CONN] Debug - Cluster y kubeconfig a usar"
  ansible.builtin.debug:
    msg: "Cluster: {{ target_cluster_name | default('N/A') }} | Kubeconfig: {{ dynamic_kubeconfig_path | default('contexto por defecto') }}"
  when: target_cluster_name is defined

# Verificación Hub vs Spoke: leer el kubeconfig del spoke y mostrar a qué API Server apunta
- name: "[CONN] Leer kubeconfig del spoke para verificar API Server"
  ansible.builtin.slurp:
    src: "/tmp/kubeconfig-{{ target_cluster_name }}"
  register: spoke_kubeconfig_raw
  when:
    - target_cluster_name is defined
    - target_cluster_name | length > 0
    - kubeconfig_file_stat.stat.exists | default(false)

- name: "[CONN] Verificación Hub vs Spoke - API Server del kubeconfig del spoke"
  ansible.builtin.set_fact:
    spoke_api_server: "{{ ((spoke_kubeconfig_raw.content | b64decode) | from_yaml).clusters[0].cluster.server }}"
  when:
    - target_cluster_name is defined
    - spoke_kubeconfig_raw.content is defined
    - spoke_kubeconfig_raw.content | length > 0

- name: "[CONN] Debug - API Server al que apunta el kubeconfig del spoke (debe ser el spoke, no el Hub)"
  ansible.builtin.debug:
    msg: |
      target_cluster_name (namespace en Hub): {{ target_cluster_name }}
      Ruta kubeconfig usado para las tareas: {{ dynamic_kubeconfig_path }}
      API Server en ese kubeconfig: {{ spoke_api_server | default('(no obtenido)') }}
      → Si la URL coincide con la del Hub, el secret admin-kubeconfig en el Hub está mal o es del Hub.
  when: target_cluster_name is defined

- name: "[INIT] Debug - Usando kubeconfig del spoke (no del Hub)"
  ansible.builtin.debug:
    msg: "Iniciando consultas al cluster con kubeconfig={{ dynamic_kubeconfig_path }} (target={{ target_cluster_name }})"
  when:
    - target_cluster_name is defined
    - dynamic_kubeconfig_path is defined

# Forzar uso del kubeconfig del spoke: anular K8S_AUTH_* del Hub para que kubernetes.core
# use solo KUBECONFIG y no la credencial inyectada por AAP (que apunta al Hub).
- name: "[SPOKE] Todas las consultas siguientes usan solo el kubeconfig del spoke"
  when: dynamic_kubeconfig_path is defined
  block:
    - name: "[INIT] Obtener infraestructura del cluster"
      kubernetes.core.k8s_info:
        api_version: config.openshift.io/v1
        kind: Infrastructure
        name: cluster
        kubeconfig: "{{ dynamic_kubeconfig_path }}"
      register: infra_info

    - name: "[INIT] Definir variables de ejecución"
      ansible.builtin.set_fact:
        cluster_name: "{{ infra_info.resources[0].status.infrastructureName | default('DESCONOCIDO') }}"
      when:
        - infra_info.resources is defined
        - infra_info.resources | length > 0

    - name: "[INIT] Debug - Infrastructure obtenida (debe ser del spoke, no del Hub)"
      ansible.builtin.debug:
        msg: |
          target_cluster_name: {{ target_cluster_name }}
          infrastructureName devuelto: {{ cluster_name | default(infra_info.resources[0].status.infrastructureName | default('N/A')) }}
          → Debe ser distinto del Hub (cluster-n55vg-sxd5g). Si coincide, aún se está usando el Hub.
      when:
        - target_cluster_name is defined
        - infra_info.resources is defined
        - infra_info.resources | length > 0

    # SECCIÓN INFORM
    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: 01_kubeadmin.yml
      when: "'ALL' in report_name or 'kubeadmin' in report_name"

    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: 02_log_forwarder.yml
      when: "'ALL' in report_name or 'logs' in report_name"

    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: 03_ingress_tls.yml
      when: "'ALL' in report_name or 'ingress' in report_name"

    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: 04_ldap_tls.yml
      when: "'ALL' in report_name or 'ldap' in report_name"

    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: 05_acs_sensor.yml
      when: "'ALL' in report_name or 'acs' in report_name"

    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: 06_network_policies.yml
      when: "'ALL' in report_name or 'network' in report_name"

    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: 07_oauth_timeouts_inform.yml
      when: "'ALL' in report_name or 'oauth' in report_name"

    - name: "[INFORM] Ejecutando revisiones de seguridad"
      ansible.builtin.include_tasks: automatic_remediation_inform.yml
      when: "'ALL' in report_name or 'remediation' in report_name"

    # FINALIZACION
    - name: "[REPORT] Generar y enviar reporte consolidado"
      ansible.builtin.include_tasks: 99_send_report.yml
  environment:
    KUBECONFIG: "{{ dynamic_kubeconfig_path }}"
    K8S_AUTH_HOST: ""
    K8S_AUTH_API_KEY: ""
    K8S_AUTH_KUBECONFIG: ""

# ---------------------------------------------------------
# LIMPIEZA: Borrar kubeconfig temporal por seguridad
# ---------------------------------------------------------
- name: "[CLEANUP] Eliminar kubeconfig temporal"
  ansible.builtin.file:
    path: "{{ dynamic_kubeconfig_path }}"
    state: absent
  when:
    - dynamic_kubeconfig_path is defined
    - dynamic_kubeconfig_path | length > 0
  delegate_to: localhost
